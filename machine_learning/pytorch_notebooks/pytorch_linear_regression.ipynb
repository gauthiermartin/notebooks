{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Linear Regression with PyTorch\n",
    "## 1. About Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Simple Linear Regression Basics\n",
    "- Allows us to understand **relationship** between two **continuous variables**\n",
    "- Example \n",
    "    - x: independent variable (X does not depend on Y)\n",
    "        - weight\n",
    "    - y: dependent variable (Y depends on X)\n",
    "        - height\n",
    "- $y = \\alpha x + \\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Example of simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)\n",
    "n = 50\n",
    "x = np.random.randn(n)\n",
    "y = x * np.random.randn(n)\n",
    "\n",
    "colors = np.random.rand(n)\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "\n",
    "plt.scatter(x, y, c=colors, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Aim of Linear Regression\n",
    "- Minimize the distance between the points and the line ($y = \\alpha x + \\beta$)\n",
    "- Adjusting\n",
    "    - Coefficient: $\\alpha$\n",
    "    - Bias/intercept: $\\beta$\n",
    "\n",
    "## 2. Building a Linear Regression Model with PyTorch\n",
    "\n",
    "### 2.1 Example\n",
    "- Coefficient: $\\alpha = 2$\n",
    "- Bias/intercept: $\\beta = 1$\n",
    "- Equation: $y = 2x + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Building a Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [i for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to numpy\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANT: 2D required\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = 2x + 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values = [2*i + 1 for i in x_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you're weak in list iterators...\n",
    "y_values = []\n",
    "for i in x_values:\n",
    "    result = 2*i + 1\n",
    "    y_values.append(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANT: 2D required\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Critical Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Model**\n",
    "1. Linear model\n",
    "    - True Equation: $y = 2x + 1$\n",
    "2. Forward\n",
    "    - Example\n",
    "        - Input $x = 1 $\n",
    "        - Output $\\hat y = ?$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate Model Class**\n",
    "- input: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "- desired output: [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LinearRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate Loss Class**\n",
    "- MSE Loss: Mean Squared Error\n",
    "- $MSE = \\frac{1}{n} \\sum_{i=1}^n(\\hat y_i - y_i)$\n",
    "    - $\\hat y$: prediction\n",
    "    - $y$: true value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate Optimizer Class**\n",
    "- Simplified equation\n",
    "    - $\\theta = \\theta - \\eta \\cdot \\nabla_\\theta $\n",
    "        - $\\theta$: parameters (our variables)\n",
    "        - $\\eta$: learning rate (how fast we want to learn)\n",
    "        - $\\nabla_\\theta$: parameters' gradients\n",
    "- Even simplier equation\n",
    "    - `parameters = parameters - learning_rate * parameters_gradients`\n",
    "        - parameters: $\\alpha$ and $\\beta$ in $ y = \\alpha x + \\beta$\n",
    "        - desired parameters: $\\alpha = 2$ and $\\beta = 1$ in $ y = 2x + 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**\n",
    "- 1 epoch: going through the whole x_train data once\n",
    "    - 100 epochs: \n",
    "        - 100x mapping `x_train = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]`\n",
    "        \n",
    "- Process \n",
    "    1. Convert inputs/labels to tensors with gradients\n",
    "    2. Clear gradient buffets\n",
    "    3. Get output given inputs \n",
    "    4. Get loss\n",
    "    5. Get gradients w.r.t. parameters\n",
    "    6. Update parameters using gradients\n",
    "        - `parameters = parameters - learning_rate * parameters_gradients`\n",
    "    7. REPEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 3.3986082144110696e-06\n",
      "epoch 2, loss 3.3609874208195833e-06\n",
      "epoch 3, loss 3.3234596230613533e-06\n",
      "epoch 4, loss 3.286183073214488e-06\n",
      "epoch 5, loss 3.249311248509912e-06\n",
      "epoch 6, loss 3.2126872611115687e-06\n",
      "epoch 7, loss 3.177578491886379e-06\n",
      "epoch 8, loss 3.1424090138898464e-06\n",
      "epoch 9, loss 3.106358462900971e-06\n",
      "epoch 10, loss 3.0719129426870495e-06\n",
      "epoch 11, loss 3.0378571409528377e-06\n",
      "epoch 12, loss 3.0038256682018982e-06\n",
      "epoch 13, loss 2.9706297937082127e-06\n",
      "epoch 14, loss 2.9367965908022597e-06\n",
      "epoch 15, loss 2.9050622742943233e-06\n",
      "epoch 16, loss 2.8718820885842433e-06\n",
      "epoch 17, loss 2.8397093956300523e-06\n",
      "epoch 18, loss 2.8081483378628036e-06\n",
      "epoch 19, loss 2.7772482553700684e-06\n",
      "epoch 20, loss 2.745791107372497e-06\n",
      "epoch 21, loss 2.7151668291480746e-06\n",
      "epoch 22, loss 2.684775381567306e-06\n",
      "epoch 23, loss 2.654508989508031e-06\n",
      "epoch 24, loss 2.625345587148331e-06\n",
      "epoch 25, loss 2.596129206722253e-06\n",
      "epoch 26, loss 2.5669849037512904e-06\n",
      "epoch 27, loss 2.537632326493622e-06\n",
      "epoch 28, loss 2.5099625418079086e-06\n",
      "epoch 29, loss 2.4815874439809704e-06\n",
      "epoch 30, loss 2.454454261169303e-06\n",
      "epoch 31, loss 2.4266118998639286e-06\n",
      "epoch 32, loss 2.400173571004416e-06\n",
      "epoch 33, loss 2.3728664473310346e-06\n",
      "epoch 34, loss 2.3467835035262397e-06\n",
      "epoch 35, loss 2.3199831957754213e-06\n",
      "epoch 36, loss 2.2937042558623943e-06\n",
      "epoch 37, loss 2.2688730041409144e-06\n",
      "epoch 38, loss 2.2434903712564847e-06\n",
      "epoch 39, loss 2.218127747255494e-06\n",
      "epoch 40, loss 2.1927376110397745e-06\n",
      "epoch 41, loss 2.1695468603866175e-06\n",
      "epoch 42, loss 2.1453065528476145e-06\n",
      "epoch 43, loss 2.121139914379455e-06\n",
      "epoch 44, loss 2.097282276736223e-06\n",
      "epoch 45, loss 2.0740656054840656e-06\n",
      "epoch 46, loss 2.0508630313997855e-06\n",
      "epoch 47, loss 2.026977881541825e-06\n",
      "epoch 48, loss 2.004973794100806e-06\n",
      "epoch 49, loss 1.9828364656859776e-06\n",
      "epoch 50, loss 1.9607500689744484e-06\n",
      "epoch 51, loss 1.9380954654479865e-06\n",
      "epoch 52, loss 1.9171045551047428e-06\n",
      "epoch 53, loss 1.8956857275043149e-06\n",
      "epoch 54, loss 1.8742262000159826e-06\n",
      "epoch 55, loss 1.8532539343141252e-06\n",
      "epoch 56, loss 1.8324660686630523e-06\n",
      "epoch 57, loss 1.8124042071576696e-06\n",
      "epoch 58, loss 1.791877593859681e-06\n",
      "epoch 59, loss 1.771476490830537e-06\n",
      "epoch 60, loss 1.7522107782497187e-06\n",
      "epoch 61, loss 1.732836608425714e-06\n",
      "epoch 62, loss 1.7134607332991436e-06\n",
      "epoch 63, loss 1.6939594615905662e-06\n",
      "epoch 64, loss 1.675871089901193e-06\n",
      "epoch 65, loss 1.65705819199502e-06\n",
      "epoch 66, loss 1.6385962453568936e-06\n",
      "epoch 67, loss 1.6200647223740816e-06\n",
      "epoch 68, loss 1.6019498616515193e-06\n",
      "epoch 69, loss 1.5842718994463212e-06\n",
      "epoch 70, loss 1.5667816342102014e-06\n",
      "epoch 71, loss 1.5484380355701433e-06\n",
      "epoch 72, loss 1.53128326019214e-06\n",
      "epoch 73, loss 1.5143825748964446e-06\n",
      "epoch 74, loss 1.4974638133935514e-06\n",
      "epoch 75, loss 1.4812011386311497e-06\n",
      "epoch 76, loss 1.4639332448496134e-06\n",
      "epoch 77, loss 1.4478091543423943e-06\n",
      "epoch 78, loss 1.4319221008918248e-06\n",
      "epoch 79, loss 1.4156095176076633e-06\n",
      "epoch 80, loss 1.3998089798406e-06\n",
      "epoch 81, loss 1.3838102859153878e-06\n",
      "epoch 82, loss 1.3687732689504628e-06\n",
      "epoch 83, loss 1.3531890772355837e-06\n",
      "epoch 84, loss 1.3377886034504627e-06\n",
      "epoch 85, loss 1.3232069022706128e-06\n",
      "epoch 86, loss 1.3086377066429122e-06\n",
      "epoch 87, loss 1.2933707012052764e-06\n",
      "epoch 88, loss 1.279779098695144e-06\n",
      "epoch 89, loss 1.26524400911876e-06\n",
      "epoch 90, loss 1.2510155329437112e-06\n",
      "epoch 91, loss 1.2368103625703952e-06\n",
      "epoch 92, loss 1.222790729116241e-06\n",
      "epoch 93, loss 1.2093809118596255e-06\n",
      "epoch 94, loss 1.1955571608268656e-06\n",
      "epoch 95, loss 1.1823949535028078e-06\n",
      "epoch 96, loss 1.169449546978285e-06\n",
      "epoch 97, loss 1.156366238319606e-06\n",
      "epoch 98, loss 1.1434473208282725e-06\n",
      "epoch 99, loss 1.1307373597446713e-06\n",
      "epoch 100, loss 1.1181404033777653e-06\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    # Convert numpy array to torch Variable\n",
    "    inputs = torch.from_numpy(x_train).requires_grad_()\n",
    "    labels = torch.from_numpy(y_train)\n",
    "\n",
    "    # Clear gradients w.r.t. parameters\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    # Forward to get output\n",
    "    outputs = model(inputs)    \n",
    "    \n",
    "    # Calculate Loss\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Getting gradients w.r.t. parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Updating parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9756333],\n",
       "       [ 2.9791424],\n",
       "       [ 4.982651 ],\n",
       "       [ 6.9861603],\n",
       "       [ 8.98967  ],\n",
       "       [10.993179 ],\n",
       "       [12.996688 ],\n",
       "       [15.000196 ],\n",
       "       [17.003706 ],\n",
       "       [19.007215 ],\n",
       "       [21.010725 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purely inference\n",
    "predicted = model(torch.from_numpy(x_train).requires_grad_()).data.numpy()\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [15.],\n",
       "       [17.],\n",
       "       [19.],\n",
       "       [21.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = 2x + 1 \n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear figure\n",
    "plt.clf()\n",
    "\n",
    "# Get predictions\n",
    "predicted = model(torch.from_numpy(x_train).requires_grad_()).data.numpy()\n",
    "\n",
    "# Plot true data\n",
    "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
    "\n",
    "# Plot predictions\n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
    "\n",
    "# Legend and plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model = False\n",
    "if save_model is True: \n",
    "    # Saves only parameters\n",
    "    # alpha & beta\n",
    "    torch.save(model.state_dict(), 'awesome_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_model = False\n",
    "if load_model is True:\n",
    "    model.load_state_dict(torch.load('awesome_model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building a Linear Regression Model with PyTorch (GPU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CPU Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "'''\n",
    "STEP 1: CREATE MODEL CLASS\n",
    "'''\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 2: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LinearRegressionModel(input_dim, output_dim)\n",
    "\n",
    "'''\n",
    "STEP 3: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 5: TRAIN THE MODEL\n",
    "'''\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    # Convert numpy array to torch Variable\n",
    "    inputs = torch.from_numpy(x_train).requires_grad_()\n",
    "    labels = torch.from_numpy(y_train)\n",
    "\n",
    "    # Clear gradients w.r.t. parameters\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    # Forward to get output\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Calculate Loss\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Getting gradients w.r.t. parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Updating parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU: 2 things must be on GPU\n",
    "- `model`\n",
    "- `tensors with gradients`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 336.0314025878906\n",
      "epoch 2, loss 27.67657470703125\n",
      "epoch 3, loss 2.5220539569854736\n",
      "epoch 4, loss 0.46732547879219055\n",
      "epoch 5, loss 0.2968060076236725\n",
      "epoch 6, loss 0.2800087630748749\n",
      "epoch 7, loss 0.27578213810920715\n",
      "epoch 8, loss 0.2726128399372101\n",
      "epoch 9, loss 0.269561231136322\n",
      "epoch 10, loss 0.2665504515171051\n",
      "epoch 11, loss 0.2635740041732788\n",
      "epoch 12, loss 0.26063060760498047\n",
      "epoch 13, loss 0.2577202618122101\n",
      "epoch 14, loss 0.2548423111438751\n",
      "epoch 15, loss 0.25199657678604126\n",
      "epoch 16, loss 0.24918246269226074\n",
      "epoch 17, loss 0.24639996886253357\n",
      "epoch 18, loss 0.24364829063415527\n",
      "epoch 19, loss 0.24092751741409302\n",
      "epoch 20, loss 0.2382371574640274\n",
      "epoch 21, loss 0.23557686805725098\n",
      "epoch 22, loss 0.2329462170600891\n",
      "epoch 23, loss 0.2303449958562851\n",
      "epoch 24, loss 0.22777271270751953\n",
      "epoch 25, loss 0.2252292037010193\n",
      "epoch 26, loss 0.22271405160427094\n",
      "epoch 27, loss 0.22022713720798492\n",
      "epoch 28, loss 0.21776780486106873\n",
      "epoch 29, loss 0.21533599495887756\n",
      "epoch 30, loss 0.21293145418167114\n",
      "epoch 31, loss 0.21055366098880768\n",
      "epoch 32, loss 0.20820240676403046\n",
      "epoch 33, loss 0.2058774083852768\n",
      "epoch 34, loss 0.20357847213745117\n",
      "epoch 35, loss 0.20130516588687897\n",
      "epoch 36, loss 0.1990572065114975\n",
      "epoch 37, loss 0.19683438539505005\n",
      "epoch 38, loss 0.19463638961315155\n",
      "epoch 39, loss 0.19246290624141693\n",
      "epoch 40, loss 0.1903136670589447\n",
      "epoch 41, loss 0.1881885528564453\n",
      "epoch 42, loss 0.18608702719211578\n",
      "epoch 43, loss 0.18400898575782776\n",
      "epoch 44, loss 0.18195408582687378\n",
      "epoch 45, loss 0.17992223799228668\n",
      "epoch 46, loss 0.17791320383548737\n",
      "epoch 47, loss 0.17592646181583405\n",
      "epoch 48, loss 0.17396186292171478\n",
      "epoch 49, loss 0.17201924324035645\n",
      "epoch 50, loss 0.17009828984737396\n",
      "epoch 51, loss 0.16819894313812256\n",
      "epoch 52, loss 0.16632060706615448\n",
      "epoch 53, loss 0.16446338593959808\n",
      "epoch 54, loss 0.16262666881084442\n",
      "epoch 55, loss 0.16081078350543976\n",
      "epoch 56, loss 0.15901507437229156\n",
      "epoch 57, loss 0.15723931789398193\n",
      "epoch 58, loss 0.15548335015773773\n",
      "epoch 59, loss 0.15374726057052612\n",
      "epoch 60, loss 0.1520303338766098\n",
      "epoch 61, loss 0.15033268928527832\n",
      "epoch 62, loss 0.14865389466285706\n",
      "epoch 63, loss 0.14699392020702362\n",
      "epoch 64, loss 0.14535246789455414\n",
      "epoch 65, loss 0.14372935891151428\n",
      "epoch 66, loss 0.14212435483932495\n",
      "epoch 67, loss 0.14053721725940704\n",
      "epoch 68, loss 0.13896773755550385\n",
      "epoch 69, loss 0.1374160647392273\n",
      "epoch 70, loss 0.1358814686536789\n",
      "epoch 71, loss 0.13436420261859894\n",
      "epoch 72, loss 0.13286370038986206\n",
      "epoch 73, loss 0.1313801407814026\n",
      "epoch 74, loss 0.12991292774677277\n",
      "epoch 75, loss 0.12846232950687408\n",
      "epoch 76, loss 0.1270277351140976\n",
      "epoch 77, loss 0.12560924887657166\n",
      "epoch 78, loss 0.12420656532049179\n",
      "epoch 79, loss 0.12281957268714905\n",
      "epoch 80, loss 0.1214480847120285\n",
      "epoch 81, loss 0.12009195983409882\n",
      "epoch 82, loss 0.1187509223818779\n",
      "epoch 83, loss 0.11742479354143143\n",
      "epoch 84, loss 0.11611353605985641\n",
      "epoch 85, loss 0.11481687426567078\n",
      "epoch 86, loss 0.11353478580713272\n",
      "epoch 87, loss 0.11226697266101837\n",
      "epoch 88, loss 0.11101329326629639\n",
      "epoch 89, loss 0.10977360606193542\n",
      "epoch 90, loss 0.10854770988225937\n",
      "epoch 91, loss 0.10733554512262344\n",
      "epoch 92, loss 0.10613703727722168\n",
      "epoch 93, loss 0.10495180636644363\n",
      "epoch 94, loss 0.10377981513738632\n",
      "epoch 95, loss 0.10262089222669601\n",
      "epoch 96, loss 0.10147502273321152\n",
      "epoch 97, loss 0.1003417894244194\n",
      "epoch 98, loss 0.09922132641077042\n",
      "epoch 99, loss 0.0981132984161377\n",
      "epoch 100, loss 0.09701769798994064\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "STEP 1: CREATE MODEL CLASS\n",
    "'''\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 2: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LinearRegressionModel(input_dim, output_dim)\n",
    "\n",
    "\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "'''\n",
    "STEP 3: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 5: TRAIN THE MODEL\n",
    "'''\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    # Convert numpy array to torch Variable\n",
    "    \n",
    "    #######################\n",
    "    #  USE GPU FOR MODEL  #\n",
    "    #######################\n",
    "    inputs = torch.from_numpy(x_train).to(device)\n",
    "    labels = torch.from_numpy(y_train).to(device)\n",
    "    \n",
    "    # Clear gradients w.r.t. parameters\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    # Forward to get output\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Calculate Loss\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Getting gradients w.r.t. parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Updating parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Logging\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simple **linear regression basics**\n",
    "    - $y = Ax + B$\n",
    "    - $y = 2x + 1$\n",
    "- **Example** of simple linear regression\n",
    "- **Aim** of linear regression\n",
    "    - Minimizing distance between the points and the line\n",
    "        - Calculate \"distance\" through `MSE`\n",
    "        - Calculate `gradients`\n",
    "        - Update parameters with `parameters = parameters - learning_rate * gradients`\n",
    "        - Slowly update parameters $A$ and $B$ model the linear relationship between $y$ and $x$ of the form $y = 2x + 1$\n",
    "- Built a linear regression **model** in **CPU and GPU**\n",
    "    - Step 1: Create Model Class\n",
    "    - Step 2: Instantiate Model Class\n",
    "    - Step 3: Instantiate Loss Class\n",
    "    - Step 4: Instantiate Optimizer Class\n",
    "    - Step 5: Train Model\n",
    "- Important things to be on **GPU**\n",
    "    - `model`\n",
    "    - `tensors with gradients`\n",
    "- How to bring to **GPU**?\n",
    "    - `model_name.cuda()`\n",
    "    - `variable_name.cuda()`"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
